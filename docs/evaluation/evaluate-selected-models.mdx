---
title: Evaluate Selected Models
description: How to evaluate selected models from your configuration file and get a summary of the results using Thabit.
---

# Evaluate Selected Models

The `eval` command takes an optional `--models` option to evaluate selected models from your configuration file.

The models should comma separated and should be the model id from the provider.

The summary will be displayed in the terminal, showing all pass and fail tests and also saved to a file in the `evals/{dataset_name}/` directory.

## Example

To evaluate the `unicode-text` dataset with the `gpt-4o`, `gpt-3.5-turbo`, and `deepseek-chat` models, you can use the following command:

```bash
thabit eval --dataset-name=unicode-text --models=gpt-4o,gpt-3.5-turbo,deepseek-chat
```

## Config Example

```json
{
  "models": [
    {
      "provider": "OpenAI",
      "model": "gpt-4o",
      "model_name": "GPT-4o",
      "endpoint": "https://api.openai.com/v1/chat/completions",
      "api_key_env_var": "OPEN_AI_API_KEY"
    },
    {
      "provider": "OpenAI",
      "model": "gpt-4o-mini",
      "model_name": "GPT-4o-mini",
      "endpoint": "https://api.openai.com/v1/chat/completions",
      "api_key_env_var": "OPEN_AI_API_KEY"
    },
    {
      "provider": "DeepSeek",
      "model": "deepseek-chat",
      "model_name": "DeepSeek-Chat",
      "endpoint": "https://api.deepseek.com/v1/chat/completions",
      "api_key_env_var": "DEEP_SEEK_API_KEY"
    },
    {
      "provider": "FireworksAI",
      "model": "accounts/fireworks/models/llama-v3p1-405b-instruct",
      "model_name": "Llama 3.1 405b",
      "endpoint": "https://api.fireworks.ai/inference/v1/chat/completions",
      "api_key_env_var": "FIREWORKS_API_KEY"
    },
    {
      "provider": "Anthropic",
      "model": "claude-3-5-sonnet-20240620",
      "model_name": "Claude 3.5 Sonnet",
      "endpoint": "https://api.anthropic.com/v1/messages",
      "api_key_env_var": "CLAUDE_API_KEY"
    },
    {
      "provider": "Cohere",
      "model": "command-r",
      "model_name": "Cohere Command R",
      "endpoint": "https://api.cohere.com/v1/chat",
      "api_key_env_var": "COHERE_API_KEY"
    },
    {
      "provider": "Cohere",
      "model": "command-r-plus",
      "model_name": "Cohere Command R+",
      "endpoint": "https://api.cohere.com/v1/chat",
      "api_key_env_var": "COHERE_API_KEY"
    }
  ],
  "global_parameters": {
    "temperature": 1,
    "max_tokens": 200,
    "top_p": 1,
    "frequency_penalty": 0,
    "presence_penalty": 0
  }
}
```
